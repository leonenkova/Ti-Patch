{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQygrfQ6LBoO"
      },
      "outputs": [],
      "source": [
        "# https://github.com/chaofengc/IQA-PyTorch/tree/main\n",
        "!pip install pyiqa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KBqyxjQ9OG_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pyiqa\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsCy0FVILHvq"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "#create metric with default settin\n",
        "iqa_metric = pyiqa.create_metric('paq2piq', device=device)\n",
        "# gradient propagation is disabled by default. set as_loss=True to enable it as a loss function.\n",
        "iqa_loss = pyiqa.create_metric('paq2piq', device=device, as_loss=True)\n",
        "\n",
        "nps_triplets_path = 'utils/npstriplets.txt'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nps and tv implementation\n",
        "my_file = open(nps_triplets_path, 'r')\n",
        "data = my_file.readlines()\n",
        "printability_list = [list(map(float, s.split(','))) for s in data]\n",
        "\n",
        "def get_printability_array(printability_list, side):\n",
        "\n",
        "    printability_array = []\n",
        "    for printability_triplet in printability_list:\n",
        "        printability_imgs = []\n",
        "        red, green, blue = printability_triplet\n",
        "\n",
        "        printability_imgs.append(np.full((side[0], side[1]), blue))\n",
        "        printability_imgs.append(np.full((side[0], side[1]), green))\n",
        "        printability_imgs.append(np.full((side[0], side[1]), red))\n",
        "\n",
        "        printability_array.append(printability_imgs)\n",
        "\n",
        "    printability_array = np.asarray(printability_array)\n",
        "    printability_array = np.float32(printability_array)\n",
        "    pa = torch.from_numpy(printability_array)\n",
        "    return pa\n",
        "\n",
        "def get_nps(printability_array, adv_patch):\n",
        "\n",
        "    color_dist = adv_patch - printability_array + 0.000001\n",
        "    color_dist = color_dist**2\n",
        "    color_dist = torch.sum(color_dist, 1) + 0.000001\n",
        "    color_dist = torch.sqrt(color_dist)\n",
        "    color_dist_prod = torch.min(color_dist, 0)[0]\n",
        "    nps_score = torch.sum(color_dist_prod, 0)\n",
        "    nps_score = torch.sum(nps_score, 0)\n",
        "    return nps_score / torch.numel(adv_patch)\n",
        "\n",
        "def get_tv(adv_patch):\n",
        "    tvcomp1 = adv_patch[:, :, 1:] - adv_patch[:, :, :-1]\n",
        "    tvcomp1 = (tvcomp1 * tvcomp1).sum()\n",
        "    tvcomp2 = adv_patch[:, 1:, :] - adv_patch[:, :-1, :]\n",
        "    tvcomp2 = (tvcomp2 * tvcomp2).sum()\n",
        "    tv = tvcomp1 + tvcomp2\n",
        "    return tv / torch.numel(adv_patch)"
      ],
      "metadata": {
        "id": "Hy8f3a2nEhCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePl2yRtNGNv_"
      },
      "outputs": [],
      "source": [
        "# Initialize the patch\n",
        "def patch_initialization(patch_size, bw_flag):\n",
        "    if bw_flag:\n",
        "      bw = np.random.rand(patch_size, patch_size)\n",
        "      patch = np.stack((bw, bw, bw))\n",
        "    else:\n",
        "      patch = np.random.rand(3, patch_size, patch_size)\n",
        "    np.clip(patch, 0.0, 1.0)\n",
        "    return patch\n",
        "\n",
        "def mask_generation(patch, image_size):\n",
        "    applied_patch = np.zeros(image_size)\n",
        "    (_, width, height) = patch.shape\n",
        "\n",
        "    # patch rotation\n",
        "    rotation_angle = np.random.choice(4)\n",
        "    for i in range(patch.shape[0]):\n",
        "        patch[i] = np.rot90(patch[i], rotation_angle)\n",
        "\n",
        "    # patch location\n",
        "    x_location, y_location = np.random.randint(low=0, high=image_size[1]-patch.shape[1]), np.random.randint(low=0, high=image_size[2]-patch.shape[2])\n",
        "\n",
        "    for i in range(3):\n",
        "        applied_patch[i, x_location:x_location + patch.shape[1], y_location:y_location + patch.shape[2]] = patch[i,:,:]\n",
        "\n",
        "    mask = applied_patch.copy()\n",
        "    mask[mask != 0] = 1.0\n",
        "    return patch, applied_patch, mask, x_location, y_location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSz5NRDAIMl7"
      },
      "outputs": [],
      "source": [
        "def center_crop_256(image):\n",
        "  center = image.shape[0]/2, image.shape[1]/2\n",
        "  if center[1] < 128 or center[0] < 128:\n",
        "    return cv2.resize(image, (256, 256))\n",
        "  x = center[1] - 128\n",
        "  y = center[0] - 128\n",
        "\n",
        "  return image[int(y):int(y+256), int(x):int(x+256)]\n",
        "\n",
        "class MyCustomDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 path_gt,\n",
        "                 mode\n",
        "                ):\n",
        "\n",
        "        self._items = []\n",
        "        self._index = 0\n",
        "        self.mode = mode\n",
        "        if mode == 'train':\n",
        "          dir_img = sorted(os.listdir(path_gt))\n",
        "        else:\n",
        "          dir_img = sorted(os.listdir(path_gt))\n",
        "        img_pathes = dir_img\n",
        "\n",
        "        for img_path in img_pathes:\n",
        "          self._items.append((\n",
        "            os.path.join(path_gt, img_path)\n",
        "          ))\n",
        "        random.shuffle(self._items)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self._items)\n",
        "\n",
        "    def next_data(self):\n",
        "      gt_path = self._items[self._index]\n",
        "      self._index += 1\n",
        "      if self._index == len(self._items):\n",
        "        self._index = 0\n",
        "        random.shuffle(self._items)\n",
        "\n",
        "      image = Image.open(gt_path).convert('RGB')\n",
        "      image = np.array(image).astype(np.float32)\n",
        "      image = center_crop_256(image)\n",
        "\n",
        "      image = image / 255.\n",
        "      image = transforms.ToTensor()(image)\n",
        "      y = image.to(device)\n",
        "      return y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      gt_path = self._items[index]\n",
        "      image = Image.open(gt_path).convert('RGB')\n",
        "      image = np.array(image).astype(np.float32)\n",
        "\n",
        "      image = center_crop_256(image)\n",
        "\n",
        "      image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "      image = transforms.RandomHorizontalFlip()(image)\n",
        "      image = transforms.RandomVerticalFlip()(image)\n",
        "      image = transforms.ToTensor()(image)\n",
        "      y = image.to(device)\n",
        "      return y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_brightness(patch, start_br):\n",
        "    br = np.mean(patch)\n",
        "\n",
        "    if br >= start_br * 1.2 :\n",
        "      brightness_factor = np.random.uniform(0.9, 1.0)\n",
        "    elif br <= start_br * 0.8 :\n",
        "      brightness_factor = np.random.uniform(1.0, 1.1)\n",
        "    else:\n",
        "      brightness_factor = np.random.uniform(0.9, 1.1)\n",
        "\n",
        "    modified_patch = np.clip(patch * brightness_factor, 0, 1)\n",
        "\n",
        "    return modified_patch"
      ],
      "metadata": {
        "id": "_l4WZYSQgMwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def patch_attack(patch_resize, last_resize, flag_br, bw_flag, patch_size, start_br, x_location, y_location, applied_patch, mask, model, lr, max_iteration):\n",
        "\n",
        "    patch = np.zeros((3, patch_size, patch_size))\n",
        "    patch = applied_patch[:, x_location:x_location + patch_size, y_location:y_location + patch_size]\n",
        "    if flag_br:\n",
        "      patch = random_brightness(patch, start_br)\n",
        "    for i in range(3):\n",
        "      applied_patch[i, x_location:x_location + patch_size, y_location:y_location + patch_size] = patch[i,:,:]\n",
        "    applied_patch1 = torch.from_numpy(applied_patch)\n",
        "    mask = torch.from_numpy(mask)\n",
        "\n",
        "    if patch_resize:\n",
        "      patch = torch.from_numpy(patch).unsqueeze(0)\n",
        "      patch, patch_size = resize_patch(patch, last_resize)\n",
        "      patch = patch.squeeze(0)\n",
        "      applied_patch1, mask, x_location, y_location = mask_applied_patch_after_resize(patch)\n",
        "\n",
        "    count = 0\n",
        "    perturbated_image = torch.mul(mask.type(torch.FloatTensor), applied_patch1.type(torch.FloatTensor)) + torch.mul((1 - mask.type(torch.FloatTensor)), image.type(torch.FloatTensor))\n",
        "\n",
        "    while count < max_iteration:\n",
        "        perturbated_image = Variable(perturbated_image.data, requires_grad=True)\n",
        "        per_image = perturbated_image\n",
        "        per_image = per_image.to(device)\n",
        "        score = model(per_image)\n",
        "        loss = (1 - score/100)\n",
        "\n",
        "        loss.backward()\n",
        "        patch_grad = perturbated_image.grad.clone().cpu()\n",
        "        if bw_flag:\n",
        "          patch_grad_mean = torch.mean(patch_grad[0], axis = 0)\n",
        "          perturbated_image.grad.data.zero_()\n",
        "          applied_patch1 = applied_patch1.cpu().numpy()\n",
        "          for i in range(3):\n",
        "            applied_patch1[i] = - lr * torch.sign(patch_grad_mean) + applied_patch1[i]\n",
        "          applied_patch1 = np.clip(applied_patch1, 0, 1)\n",
        "        else:\n",
        "          perturbated_image.grad.data.zero_()\n",
        "          applied_patch1 = - lr * torch.sign(patch_grad) + applied_patch1.type(torch.FloatTensor)\n",
        "          applied_patch1 = torch.clamp(applied_patch1, min=0, max=1)\n",
        "          applied_patch1 = applied_patch1.cpu().numpy().squeeze()\n",
        "\n",
        "        patch = applied_patch1[:, x_location:x_location + patch_size, y_location:y_location + patch_size]\n",
        "        applied_patch1 = torch.from_numpy(applied_patch1)\n",
        "\n",
        "        perturbated_image = torch.mul(mask.type(torch.FloatTensor), applied_patch1.type(torch.FloatTensor)) + torch.mul((1-mask.type(torch.FloatTensor)), image.type(torch.FloatTensor))\n",
        "        perturbated_image = torch.clamp(perturbated_image, min=0, max=1)\n",
        "        perturbated_image = perturbated_image.to(device)\n",
        "        count += 1\n",
        "\n",
        "    patch = torch.tensor(patch, requires_grad=True, device=device, dtype=torch.float32)\n",
        "    patch = patch.to(device)\n",
        "    tv = get_tv(patch)\n",
        "    loss = tv\n",
        "    loss.backward()\n",
        "    patch_grad = patch.grad.clone().cpu()\n",
        "    if bw_flag:\n",
        "      patch_grad_mean = torch.mean(patch_grad[0], axis = 0)\n",
        "      patch.grad.data.zero_()\n",
        "      patch = patch.cpu().detach().numpy()\n",
        "      for i in range(3):\n",
        "        patch[i] = - lr * torch.sign(patch_grad_mean) + patch[i]\n",
        "      patch = np.clip(patch, 0, 1)\n",
        "    else:\n",
        "      patch.grad.data.zero_()\n",
        "      patch = - lr * torch.sign(patch_grad) + patch.type(torch.FloatTensor)\n",
        "      patch = torch.clamp(patch, min=0, max=1)\n",
        "      patch = patch.cpu().detach().numpy()\n",
        "    applied_patch1 = applied_patch1.cpu().numpy()\n",
        "    for i in range(3):\n",
        "      applied_patch1[i, x_location:x_location + patch_size, y_location:y_location + patch_size] = patch[i,:,:]\n",
        "\n",
        "    if bw_flag is False:\n",
        "      patch = torch.tensor(patch, requires_grad=True, device=device, dtype=torch.float32)\n",
        "      patch = patch.to(device)\n",
        "      pa = get_printability_array(printability_list, (patch_size, patch_size))\n",
        "      pa = pa.to(device)\n",
        "      nps = get_nps(pa, patch)\n",
        "      loss = nps\n",
        "      loss.backward()\n",
        "      patch_grad = patch.grad.clone().cpu()\n",
        "      patch.grad.data.zero_()\n",
        "      patch = - lr * torch.sign(patch_grad) + patch.type(torch.FloatTensor)\n",
        "      patch = torch.clamp(patch, min=0, max=1)\n",
        "      patch = patch.to(device)\n",
        "      patch = patch.cpu().detach().numpy()\n",
        "      for i in range(3):\n",
        "        applied_patch1[i, x_location:x_location + patch_size, y_location:y_location + patch_size] = patch[i,:,:]\n",
        "    perturbated_image = perturbated_image.cpu().numpy()\n",
        "    return perturbated_image, applied_patch1, patch_size, x_location, y_location"
      ],
      "metadata": {
        "id": "6Xwuc3PRUjgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLfJYuBeNgk5"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "def dataloader():\n",
        "\n",
        "    path_train = '/content/gdrive/MyDrive/trainn/'\n",
        "    path_test = '/content/gdrive/MyDrive/testt/'\n",
        "\n",
        "    train_dataset = MyCustomDataset(path_gt=path_train, mode=\"train\")\n",
        "    test_dataset =  MyCustomDataset(path_gt=path_test, mode=\"test\")\n",
        "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
        "    test_loader =  DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_patch(patch, flag):\n",
        "    original_size = patch.shape[2]\n",
        "    if flag:\n",
        "      new_size = 100\n",
        "    else:\n",
        "      new_size = np.random.randint(80, 161)\n",
        "    resize_factor = new_size / original_size\n",
        "    resized_patch = F.interpolate(patch, scale_factor=resize_factor, mode='bicubic', align_corners=False)\n",
        "    return resized_patch, new_size\n",
        "\n",
        "def mask_applied_patch_after_resize(patch):\n",
        "  applied_patch = np.zeros((3, 256, 256))\n",
        "  patch1 = patch.detach().cpu().numpy()\n",
        "  x_location, y_location = np.random.randint(low=0, high=256-patch1.shape[1]), np.random.randint(low=0, high=256-patch1.shape[2])\n",
        "  applied_patch[:, x_location:x_location + patch1.shape[1], y_location:y_location + patch1.shape[2]] = patch1[:,:,:]\n",
        "  mask = applied_patch.copy()\n",
        "  mask[mask != 0] = 1.0\n",
        "  applied_patch = torch.from_numpy(applied_patch)\n",
        "  mask = torch.from_numpy(mask)\n",
        "  return applied_patch, mask, x_location, y_location"
      ],
      "metadata": {
        "id": "uHFnplygZQZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCFuk_QINNQR"
      },
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame({'epoch':[],\n",
        "                   'gain':[],\n",
        "                    })\n",
        "df2 = pd.DataFrame({'epoch':[],\n",
        "                   'gain':[]\n",
        "                    })\n",
        "\n",
        "n_epochs = 10\n",
        "lr = 0.005\n",
        "max_iteration = 10\n",
        "bw_flag = True                  # if you want to generate black-white patch\n",
        "patch_size = 100                # the size of generated patch will be 3 х patch_size х patch_size\n",
        "flag_resize = True              # if you want to add random resize of the patch\n",
        "flag_br = False                 # if you want to add random brightness application to the patch\n",
        "last_resize = False\n",
        "saving_path = '...'\n",
        "\n",
        "transform = transforms.ColorJitter(brightness=(0.8,1.2))\n",
        "\n",
        "model = iqa_loss\n",
        "\n",
        "train_loader, test_loader = dataloader()\n",
        "\n",
        "# Initialize the patch\n",
        "patch = patch_initialization(patch_size, bw_flag)\n",
        "start_br = np.mean(patch)\n",
        "\n",
        "# Generate the patch\n",
        "for epoch in range(n_epochs):\n",
        "    # Train\n",
        "    print(epoch)\n",
        "    last_resize = False\n",
        "    num_im = 0\n",
        "    for image in train_loader:\n",
        "        assert image.shape[0] == 1, 'Only one picture should be loaded each time.'\n",
        "        image = image.to(device)\n",
        "        patch, applied_patch, mask, x_location, y_location = mask_generation(patch, image_size=(3, 256, 256))\n",
        "        if epoch == n_epochs-1 and num_im == len(train_loader.dataset)-1:\n",
        "          last_resize = True\n",
        "        perturbated_image, applied_patch, patch_size, x_location, y_location = patch_attack(flag_resize, last_resize, flag_br, bw_flag, patch_size, start_br, x_location, y_location, applied_patch, mask, model, lr, max_iteration)\n",
        "        patch = applied_patch[:, x_location:x_location + patch_size, y_location:y_location + patch_size]\n",
        "        num_im += 1\n",
        "\n",
        "\n",
        "    # Save train gain\n",
        "    (_, y_patch, x_patch) = patch.shape\n",
        "    gain_list = []\n",
        "    for image in train_loader:\n",
        "      image = image.squeeze().cpu().numpy()\n",
        "      x_location, y_location = np.random.randint(low=0, high=image.shape[1]-y_patch), np.random.randint(low=0, high=image.shape[2]-x_patch)\n",
        "      perturbated_image = image.copy()\n",
        "      perturbated_image[:, x_location:x_location + x_patch, y_location:y_location + y_patch] = patch\n",
        "\n",
        "      image = torch.from_numpy(image).to(device)\n",
        "      image = image.unsqueeze_(0)\n",
        "      score_before = iqa_metric(image).squeeze().item()\n",
        "\n",
        "      perturbated_image = torch.from_numpy(perturbated_image).to(device)\n",
        "      perturbated_image = perturbated_image.unsqueeze_(0)\n",
        "      score_after = iqa_metric(perturbated_image).squeeze().item()\n",
        "\n",
        "      gain = score_after - score_before\n",
        "      gain_list.append(gain)\n",
        "\n",
        "    print(f'Train gain on {epoch} epoch is {np.array(gain_list).mean()}')\n",
        "    df1.loc[len(df1.index)] = [epoch, np.array(gain_list).mean()]\n",
        "\n",
        "    # save the generated patch\n",
        "    res = patch.transpose(1, 2, 0)\n",
        "    res = (res * 255).astype('uint8')\n",
        "    res = cv2.cvtColor(res, cv2.COLOR_RGB2BGR)\n",
        "    # cv2.imwrite(saving_path, res)\n",
        "\n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        for image in test_loader:\n",
        "          assert image.shape[0] == 1, 'Only one picture should be loaded each time.'\n",
        "          image = image.to(device)\n",
        "          output = model(image)\n",
        "          applied_patch = torch.from_numpy(applied_patch)\n",
        "          mask = torch.from_numpy(mask)\n",
        "          count = 0\n",
        "          perturbated_image = torch.mul(mask.type(torch.FloatTensor), applied_patch.type(torch.FloatTensor)) + torch.mul((1 - mask.type(torch.FloatTensor)), image.type(torch.FloatTensor))\n",
        "          while count < max_iteration:\n",
        "            count += 1\n",
        "            perturbated_image = Variable(perturbated_image.data, requires_grad=True)\n",
        "            per_image = perturbated_image\n",
        "            per_image = per_image.to(device)\n",
        "            score = model(per_image)\n",
        "            loss = 1 - score / 100\n",
        "            perturbated_image = torch.mul(mask.type(torch.FloatTensor), applied_patch.type(torch.FloatTensor)) + torch.mul((1-mask.type(torch.FloatTensor)), image.type(torch.FloatTensor))\n",
        "            perturbated_image = torch.clamp(perturbated_image, min=0, max=1)\n",
        "            perturbated_image = perturbated_image.to(device)\n",
        "          perturbated_image = perturbated_image.cpu().numpy()\n",
        "          applied_patch = applied_patch.cpu().numpy()\n",
        "          mask = mask.cpu().numpy()\n",
        "          perturbated_image = torch.from_numpy(perturbated_image).to(device)\n",
        "\n",
        "    # Save valid gain\n",
        "    (_, y_patch, x_patch) = patch.shape\n",
        "    gain_list = []\n",
        "    for image in test_loader:\n",
        "      image = image.squeeze().cpu().numpy()\n",
        "      x_location, y_location = np.random.randint(low=0, high=image.shape[1]-y_patch), np.random.randint(low=0, high=image.shape[2]-x_patch)\n",
        "      perturbated_image = image.copy()\n",
        "      perturbated_image[:, x_location:x_location + x_patch, y_location:y_location + y_patch] = patch\n",
        "\n",
        "      image = torch.from_numpy(image).to(device)\n",
        "      image = image.unsqueeze_(0)\n",
        "      score_before = iqa_metric(image).squeeze().item()\n",
        "\n",
        "      perturbated_image = torch.from_numpy(perturbated_image).to(device)\n",
        "      perturbated_image = perturbated_image.unsqueeze_(0)\n",
        "      score_after = iqa_metric(perturbated_image).squeeze().item()\n",
        "\n",
        "      gain = score_after - score_before\n",
        "      gain_list.append(gain)\n",
        "\n",
        "    print(f'Valid gain on {epoch} epoch is  {np.array(gain_list).mean()}')\n",
        "    df2.loc[len(df2.index)] = [epoch, np.array(gain_list).mean()]\n",
        "\n",
        "df1[\"gain\"].plot(xlabel = 'epoch', ylabel = 'gain', title = 'train')\n",
        "fig1 = plt.gcf()\n",
        "plt.show()\n",
        "plt.draw()\n",
        "\n",
        "df2[\"gain\"].plot(xlabel = 'epoch', ylabel = 'gain', title = 'valid')\n",
        "fig1 = plt.gcf()\n",
        "plt.show()\n",
        "plt.draw()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}